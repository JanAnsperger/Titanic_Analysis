{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://deepnote.com/app/leonard-puttmann-a8ef/Titanic-Dataset-544c6818-f79a-4068-bbc1-d6fdf42d2998"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorbereitung des Datensatzes für das Modell\n",
    "\n",
    "Der Titanic-Datensatz wird für das Training eines maschinellen Lernmodells vorbereitet. Dabei wird der Datensatz in **X** (Merkmale) und **y** (Zielvariable) unterteilt.  \n",
    "\n",
    "**X** enthält die wichtigsten Features, die entweder eine hohe Korrelation aufweisen oder als relevant erscheinen. Diese sind in `feature_cols` definiert.  \n",
    "\n",
    "**y** enthält die Zielvariable `survived`, die angibt, ob eine Person überlebt hat (1) oder nicht (0). Da das Modell seine Vorhersagen anhand dieser Variable überprüft und anpasst, handelt es sich um **überwachtes maschinelles Lernen**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape von X: (891, 6)\n",
      "Shape von y: (891,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Titanic-Datensatz aus Seaborn laden\n",
    "titanic = sns.load_dataset(\"titanic\").copy()\n",
    "\n",
    "# Fehlende Werte auffüllen\n",
    "titanic[\"age\"] = titanic[\"age\"].fillna(titanic[\"age\"].median())\n",
    "titanic[\"embarked\"] = titanic[\"embarked\"].fillna(titanic[\"embarked\"].mode()[0])\n",
    "titanic[\"fare\"] = titanic[\"fare\"].fillna(titanic[\"fare\"].median())\n",
    "\n",
    "# Feature-Auswahl\n",
    "feature_cols = [\"pclass\", \"age\", \"parch\", \"sex\", \"sibsp\", \"embarked\"]\n",
    "\n",
    "# Auswahl der Features für X\n",
    "X = titanic.loc[:, feature_cols]\n",
    "print(\"Shape von X:\", X.shape)\n",
    "\n",
    "# Zielvariable y (hat die Person überlebt?)\n",
    "y = titanic[\"survived\"]\n",
    "print(\"Shape von y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufbau eines maschinellen Lernmodells  \n",
    "\n",
    "Wir setzen ein Modell auf, das vorhersagen soll, ob eine Person auf der Titanic überlebt hat. Dazu nutzen wir zunächst eine **logistische Regression**, da sie einfach umzusetzen ist.  \n",
    "\n",
    "Die logistische Regression analysiert die Abhängigkeit zwischen einer **binären Zielvariable** (0 = nicht überlebt, 1 = überlebt) und mehreren unabhängigen Variablen.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit: 79.80%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Logistisches Regressionsmodell erstellen\n",
    "logistic_reg = LogisticRegression()\n",
    "\n",
    "# Training mit X und y\n",
    "logistic_reg.fit(X, y)\n",
    "\n",
    "# Vorhersagen auf den Trainingsdaten treffen\n",
    "pred_lr = logistic_reg.predict(X)\n",
    "\n",
    "# Genauigkeit berechnen und in Prozent ausgeben\n",
    "accuracy = accuracy_score(y, pred_lr) * 100\n",
    "print(f\"Genauigkeit: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Erste Genauigkeit des Modells  \n",
    "\n",
    "Ohne Hyperparameter-Tuning erreicht unser Modell bereits eine Genauigkeit von ca. **80 %**.  \n",
    "Dieser Wert kann je nach Datensplit leicht schwanken.  \n",
    "\n",
    "Nun setzen wir eine **Pipeline** auf und nutzen **GridSearchCV**, um die Modellleistung weiter zu optimieren.  \n",
    "Dadurch können wir die besten Hyperparameter automatisch ermitteln und die Genauigkeit möglicherweise verbessern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufteilung der Daten in Trainings- und Testsatz  \n",
    "\n",
    "Bevor wir das Modell weiter optimieren, teilen wir die Daten in einen **Trainings-** und einen **Testsatz** auf.  \n",
    "- **Trainingssatz**: Wird genutzt, um das Modell zu trainieren.  \n",
    "- **Testsatz**: Bleibt unberührt, um später die Modellleistung auf unbekannten Daten zu überprüfen.  \n",
    "\n",
    "Dies stellt sicher, dass unser Modell **nicht nur die Trainingsdaten auswendig lernt**, sondern auf neue Daten verallgemeinern kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Beste Parameter: {'logistic_Reg__C': np.float64(0.01), 'logistic_Reg__penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Aufteilen in Trainings- und Testdaten (Testdaten: 20%, Trainingsdaten: 80%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline mit StandardScaler und log. Regression\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('logistic_Reg', LogisticRegression(max_iter=500, solver='liblinear'))  # ⚠️ Solver angepasst\n",
    "])\n",
    "\n",
    "# Hyperparameter für GridSearch\n",
    "werte_raster = {\n",
    "    'logistic_Reg__C': np.logspace(-4, 4, 5),\n",
    "    'logistic_Reg__penalty': ['l1', 'l2']  # ⚠️ 'none' entfernt\n",
    "}\n",
    "\n",
    "# GridSearchCV mit Kreuzvalidierung\n",
    "model_lr = GridSearchCV(pipe, param_grid=werte_raster, cv=5, verbose=True)\n",
    "\n",
    "# Training des Modells\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Beste Parameter ausgeben\n",
    "print(f\"Beste Parameter: {model_lr.best_params_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
